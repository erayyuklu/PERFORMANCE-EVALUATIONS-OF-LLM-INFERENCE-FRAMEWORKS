# =============================================================================
# GKE vLLM Deployment Configuration
# =============================================================================
# Edit these values to customize your deployment.
# All scripts source this file automatically.
# =============================================================================

# --- GCP Settings ---
# Project ID is fetched automatically from gcloud. Override here if needed.
# PROJECT_ID="my-project-id"
REGION="europe-west3"
ZONE="europe-west3-b"

# --- GKE Cluster ---
CLUSTER_NAME="vllm-cluster"
CLUSTER_VERSION="latest"
NODE_POOL_NAME="gpu-pool"
MACHINE_TYPE="g2-standard-8"
GPU_TYPE="nvidia-l4"
GPU_COUNT="1"
NUM_GPU_NODES="1"
DISK_SIZE_GB="100"

# --- Model ---
MODEL_NAME="deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
VLLM_IMAGE="vllm/vllm-openai:latest"

# --- vLLM Settings ---
MAX_MODEL_LEN="4096"
GPU_MEMORY_UTILIZATION="0.90"
DTYPE="half"
TENSOR_PARALLEL_SIZE="1"

# --- Kubernetes ---
K8S_NAMESPACE="vllm"
DEPLOYMENT_NAME="vllm-server"
SERVICE_NAME="vllm-service"
SERVICE_PORT="8000"
REPLICAS="1"

# --- Resource Requests ---
CPU_REQUEST="4"
CPU_LIMIT="6"
MEMORY_REQUEST="16Gi"
MEMORY_LIMIT="24Gi"

# --- Budget Alert ---
BUDGET_AMOUNT="200"
BUDGET_DISPLAY_NAME="vllm-budget"
BUDGET_THRESHOLD="1.0"
PUBSUB_TOPIC="budget-alert-topic"
FUNCTION_NAME="stop-billing"
FUNCTION_RUNTIME="python312"
FUNCTION_ENTRY_POINT="stop_billing"
FUNCTION_REGION="${REGION}"
